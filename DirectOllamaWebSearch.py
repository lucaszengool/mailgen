#!/usr/bin/env python3
"""
Direct Ollama Web Search Email Finder
ç›´æ¥è®©Ollamaå…·å¤‡è”ç½‘æœç´¢èƒ½åŠ›ï¼Œè¿”å›çœŸå®é‚®ç®±
- æœ¬åœ°Ollama LLM
- ç›´æ¥ç½‘ç»œæœç´¢(DuckDuckGo + Bing)
- Function Calling for web search
- æ™ºèƒ½é‚®ç®±æå–å’ŒéªŒè¯
- å®Œå…¨è‡ªä¸»ï¼Œå®æ—¶æœç´¢
"""

import sys
import json
import time
import re
import requests
import os
from datetime import datetime
from urllib.parse import quote, unquote
from bs4 import BeautifulSoup
import random

class DirectOllamaWebSearch:
    def __init__(self):
        # æœ¬åœ°Ollamaé…ç½®
        self.ollama_url = 'http://localhost:11434'
        
        # æœç´¢ä¼šè¯é…ç½®
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache'
        })
        
        # é‚®ç®±åŒ¹é…å’ŒéªŒè¯
        self.email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        
        print("ğŸ” Direct Ollama Web Search Email Finder åˆå§‹åŒ–")
        print("   ğŸ§  AIå¼•æ“: æœ¬åœ°Ollama with Function Calling")
        print("   ğŸŒ æœç´¢å¼•æ“: DuckDuckGo + Bing (ç›´æ¥)")
        print("   ğŸ“§ é‚®ç®±å‘ç°: å®æ—¶æœç´¢ + æ™ºèƒ½æå–")
        print("   âš¡ ç‰¹ç‚¹: Ollamaç›´æ¥å…·å¤‡è”ç½‘èƒ½åŠ›")
        
    def search_duckduckgo(self, query, num_results=15):
        """DuckDuckGoæœç´¢"""
        try:
            print(f"   ğŸ¦† DuckDuckGoæœç´¢: {query}")
            
            search_url = f"https://duckduckgo.com/html/?q={quote(query)}"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                results = []
                
                # æå–æœç´¢ç»“æœ
                for i, link in enumerate(soup.find_all('a', class_='result__a')[:num_results]):
                    try:
                        title = link.get_text().strip()
                        url = link.get('href', '')
                        
                        # è·å–æè¿°
                        parent = link.find_parent('div', class_='result')
                        description = ''
                        if parent:
                            snippet = parent.find('a', class_='result__snippet')
                            if snippet:
                                description = snippet.get_text().strip()
                        
                        if title and url and 'duckduckgo.com' not in url:
                            results.append({
                                'title': title,
                                'url': url,
                                'description': description,
                                'engine': 'duckduckgo',
                                'position': i + 1
                            })
                    except:
                        continue
                
                print(f"      âœ… DuckDuckGo: {len(results)}ä¸ªç»“æœ")
                return results
            else:
                print(f"      âŒ DuckDuckGoå¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"      âŒ DuckDuckGoé”™è¯¯: {str(e)}")
            return []
    
    def search_bing(self, query, num_results=15):
        """Bingæœç´¢"""
        try:
            print(f"   ğŸ” Bingæœç´¢: {query}")
            
            search_url = f"https://www.bing.com/search?q={quote(query)}&count={num_results}"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                results = []
                
                # Bingç»“æœæå–
                for i, result in enumerate(soup.find_all('li', class_='b_algo')[:num_results]):
                    try:
                        title_elem = result.find('h2')
                        if not title_elem:
                            continue
                            
                        link_elem = title_elem.find('a')
                        if not link_elem:
                            continue
                            
                        title = title_elem.get_text().strip()
                        url = link_elem.get('href', '')
                        
                        # è·å–æè¿°
                        desc_elem = result.find('div', class_='b_caption')
                        description = desc_elem.get_text().strip() if desc_elem else ''
                        
                        if title and url and 'bing.com' not in url and 'microsoft.com' not in url:
                            results.append({
                                'title': title,
                                'url': url,
                                'description': description,
                                'engine': 'bing',
                                'position': i + 1
                            })
                    except:
                        continue
                
                print(f"      âœ… Bing: {len(results)}ä¸ªç»“æœ")
                return results
            else:
                print(f"      âŒ Bingå¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"      âŒ Bingé”™è¯¯: {str(e)}")
            return []
    
    def scrape_website_for_emails(self, url):
        """æŠ“å–ç½‘ç«™å†…å®¹å¯»æ‰¾é‚®ç®±"""
        try:
            print(f"      ğŸŒ æŠ“å–: {url[:50]}...")
            
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ç§»é™¤æ— ç”¨å…ƒç´ 
                for element in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    element.decompose()
                
                # æå–æ–‡æœ¬
                text = soup.get_text()
                
                # æŸ¥æ‰¾é‚®ç®±
                emails = self.email_pattern.findall(text)
                
                # è¿‡æ»¤æœ‰æ•ˆé‚®ç®±
                valid_emails = []
                for email in emails:
                    if self.is_valid_business_email(email):
                        valid_emails.append(email)
                
                if valid_emails:
                    print(f"         âœ… æ‰¾åˆ°{len(valid_emails)}ä¸ªé‚®ç®±")
                    return {
                        'url': url,
                        'emails': valid_emails,
                        'title': soup.find('title').get_text().strip() if soup.find('title') else '',
                        'content_length': len(text)
                    }
                else:
                    print(f"         âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆé‚®ç®±")
                    return None
                    
            else:
                print(f"         âŒ æŠ“å–å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"         âŒ æŠ“å–é”™è¯¯: {str(e)}")
            return None
    
    def is_valid_business_email(self, email):
        """éªŒè¯å•†ä¸šé‚®ç®±"""
        email_lower = email.lower()
        
        # æ’é™¤æ˜æ˜¾å‡é‚®ç®±
        invalid_patterns = [
            'example.com', 'test.com', 'domain.com', 'yoursite.com',
            'noreply', 'no-reply', 'donotreply', 'privacy@', 'legal@',
            'support@example', 'admin@example', 'info@example',
            'contact@example', 'sales@example', 'yourname@',
            'name@company', 'email@website', 'user@domain'
        ]
        
        if any(pattern in email_lower for pattern in invalid_patterns):
            return False
        
        # åŸºæœ¬æ ¼å¼éªŒè¯
        if 5 < len(email) < 100 and email.count('@') == 1:
            domain = email.split('@')[1]
            if '.' in domain and len(domain) > 4:
                return True
        
        return False
    
    def web_search_and_extract_emails(self, query, max_results=20):
        """æ‰§è¡Œç½‘ç»œæœç´¢å¹¶æå–é‚®ç®± - è¿™æ˜¯Ollamaè°ƒç”¨çš„æ ¸å¿ƒfunction"""
        try:
            print(f"ğŸ” å¼€å§‹ç½‘ç»œæœç´¢: {query}")
            
            all_results = []
            all_emails = []
            
            # 1. DuckDuckGoæœç´¢
            ddg_results = self.search_duckduckgo(query, max_results//2)
            all_results.extend(ddg_results)
            
            # æœç´¢é—´éš”
            time.sleep(2)
            
            # 2. Bingæœç´¢
            bing_results = self.search_bing(query, max_results//2)
            all_results.extend(bing_results)
            
            print(f"   ğŸ“Š æ€»æœç´¢ç»“æœ: {len(all_results)}ä¸ª")
            
            # 3. ä»æœç´¢ç»“æœä¸­æå–é‚®ç®±
            print(f"   ğŸ“§ ä»æœç´¢ç»“æœæè¿°ä¸­æå–é‚®ç®±...")
            for result in all_results:
                # ä»æ ‡é¢˜å’Œæè¿°ä¸­ç›´æ¥æå–é‚®ç®±
                text_to_check = f"{result['title']} {result['description']}"
                emails_in_text = self.email_pattern.findall(text_to_check)
                
                for email in emails_in_text:
                    if self.is_valid_business_email(email):
                        all_emails.append({
                            'email': email,
                            'source': 'search_result',
                            'source_url': result['url'],
                            'source_title': result['title'],
                            'engine': result['engine']
                        })
            
            # 4. æŠ“å–å‰10ä¸ªæœ€æœ‰å‰æ™¯çš„ç½‘ç«™
            print(f"   ğŸŒ æŠ“å–å‰10ä¸ªç½‘ç«™å¯»æ‰¾æ›´å¤šé‚®ç®±...")
            priority_urls = []
            
            # ä¼˜å…ˆé€‰æ‹©åŒ…å«contact, about, teamç­‰å…³é”®è¯çš„ç»“æœ
            priority_keywords = ['contact', 'about', 'team', 'company', 'email']
            for result in all_results:
                url_lower = result['url'].lower()
                title_lower = result['title'].lower()
                if any(keyword in url_lower or keyword in title_lower for keyword in priority_keywords):
                    priority_urls.append(result['url'])
            
            # å¦‚æœä¼˜å…ˆURLä¸å¤Ÿï¼Œæ·»åŠ å…¶ä»–URL
            for result in all_results:
                if result['url'] not in priority_urls:
                    priority_urls.append(result['url'])
                if len(priority_urls) >= 10:
                    break
            
            # æŠ“å–ç½‘ç«™
            for url in priority_urls[:10]:
                website_data = self.scrape_website_for_emails(url)
                if website_data and website_data['emails']:
                    for email in website_data['emails']:
                        all_emails.append({
                            'email': email,
                            'source': 'website_scraping',
                            'source_url': url,
                            'source_title': website_data['title'],
                            'engine': 'direct_scraping'
                        })
                
                # æŠ“å–é—´éš”
                time.sleep(1)
            
            # 5. å»é‡å¹¶æ•´ç†ç»“æœ
            unique_emails = {}
            for email_data in all_emails:
                email = email_data['email']
                if email not in unique_emails:
                    unique_emails[email] = email_data
            
            final_emails = list(unique_emails.values())
            
            print(f"   âœ… ç½‘ç»œæœç´¢å®Œæˆï¼Œå‘ç°{len(final_emails)}ä¸ªå”¯ä¸€é‚®ç®±")
            
            return {
                'success': True,
                'query': query,
                'total_search_results': len(all_results),
                'emails_found': len(final_emails),
                'emails': final_emails,
                'search_engines_used': ['duckduckgo', 'bing'],
                'websites_scraped': len(priority_urls)
            }
            
        except Exception as e:
            print(f"   âŒ ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'emails': []
            }
    
    def call_ollama_with_web_search(self, prompt, model='llama3.2'):
        """è°ƒç”¨Ollamaå¹¶æä¾›ç½‘ç»œæœç´¢èƒ½åŠ›"""
        try:
            print(f"ğŸ§  è°ƒç”¨Ollama ({model}) with ç½‘ç»œæœç´¢èƒ½åŠ›...")
            
            # å®šä¹‰ç½‘ç»œæœç´¢å·¥å…·
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "web_search_emails",
                        "description": "Search the web for company email addresses using multiple search engines",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "Search query to find company emails (e.g., 'AI startup company email contact')"
                                },
                                "max_results": {
                                    "type": "integer",
                                    "description": "Maximum search results to process",
                                    "default": 20
                                }
                            },
                            "required": ["query"]
                        }
                    }
                }
            ]
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨Ollama
            response = requests.post(f"{self.ollama_url}/api/chat", json={
                'model': model,
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'tools': tools,
                'stream': False,
                'options': {
                    'temperature': 0.7,
                    'num_ctx': 4096
                }
            }, timeout=60)
            
            if response.status_code == 200:
                data = response.json()
                message = data.get('message', {})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                tool_calls = message.get('tool_calls', [])
                
                if tool_calls:
                    print(f"   ğŸ› ï¸  Ollamaè¯·æ±‚è¿›è¡Œ{len(tool_calls)}æ¬¡ç½‘ç»œæœç´¢")
                    
                    # æ‰§è¡Œç½‘ç»œæœç´¢
                    tool_results = []
                    for i, tool_call in enumerate(tool_calls):
                        function_name = tool_call['function']['name']
                        arguments = tool_call['function']['arguments']
                        
                        print(f"      ğŸ”§ æ‰§è¡Œæœç´¢ {i+1}: {function_name}")
                        
                        if function_name == 'web_search_emails':
                            result = self.web_search_and_extract_emails(**arguments)
                            tool_results.append({
                                'tool_call_id': tool_call.get('id', f'call_{i}'),
                                'function_name': function_name,
                                'result': result
                            })
                        
                        # æœç´¢é—´éš”
                        time.sleep(3)
                    
                    # å°†æœç´¢ç»“æœå‘é€å›Ollama
                    if tool_results:
                        print(f"   ğŸ§  å°†æœç´¢ç»“æœå‘é€å›Ollamaè¿›è¡Œåˆ†æ...")
                        
                        messages = [
                            {'role': 'user', 'content': prompt},
                            message,
                        ]
                        
                        # æ·»åŠ å·¥å…·ç»“æœ
                        for tool_result in tool_results:
                            messages.append({
                                'role': 'tool',
                                'content': json.dumps(tool_result['result'], ensure_ascii=False),
                                'tool_call_id': tool_result['tool_call_id']
                            })
                        
                        # æœ€ç»ˆè°ƒç”¨
                        final_response = requests.post(f"{self.ollama_url}/api/chat", json={
                            'model': model,
                            'messages': messages,
                            'stream': False,
                            'options': {
                                'temperature': 0.3,
                                'num_ctx': 4096
                            }
                        }, timeout=60)
                        
                        if final_response.status_code == 200:
                            final_data = final_response.json()
                            final_message = final_data.get('message', {})
                            
                            return {
                                'success': True,
                                'response': final_message.get('content', ''),
                                'tool_calls': tool_calls,
                                'tool_results': tool_results
                            }
                
                # æ²¡æœ‰å·¥å…·è°ƒç”¨çš„æ™®é€šå“åº”
                return {
                    'success': True,
                    'response': message.get('content', ''),
                    'tool_calls': [],
                    'tool_results': []
                }
            else:
                return {'success': False, 'error': f'Ollama API error: {response.status_code}'}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def find_emails_with_ollama_web_search(self, industry, max_emails=5):
        """ä½¿ç”¨å…·å¤‡ç½‘ç»œæœç´¢èƒ½åŠ›çš„Ollamaå‘ç°é‚®ç®±"""
        print(f"ğŸ¤– å¯åŠ¨Ollamaç½‘ç»œæœç´¢é‚®ç®±å‘ç°: {industry}")
        print(f"ğŸ¯ ç›®æ ‡: {max_emails}ä¸ªé‚®ç®±")
        print("=" * 60)
        
        # æ„å»ºæ™ºèƒ½prompt
        prompt = f"""æˆ‘éœ€è¦ä½ å¸®æˆ‘æ‰¾åˆ°{industry}è¡Œä¸šçš„çœŸå®å…¬å¸é‚®ç®±åœ°å€ã€‚

è¯·ä½¿ç”¨web_search_emailså·¥å…·è¿›è¡Œä»¥ä¸‹æœç´¢:
1. é¦–å…ˆæœç´¢ "{industry} company contact email address"
2. å¦‚æœéœ€è¦æ›´å¤šé‚®ç®±ï¼Œå†æœç´¢ "{industry} business CEO founder email"
3. å¦‚æœè¿˜éœ€è¦ï¼Œæœç´¢ "{industry} company customer service contact"

é‡è¦è¦æ±‚:
- åªè¿”å›çœŸå®çš„å•†ä¸šé‚®ç®±åœ°å€ï¼Œä¸è¦example.comç­‰å‡é‚®ç®±
- é‡ç‚¹å¯»æ‰¾å…¬å¸è”ç³»é‚®ç®±ã€CEOé‚®ç®±ã€é”€å”®é‚®ç®±
- å°½é‡æ‰¾åˆ°è‡³å°‘{max_emails}ä¸ªä¸åŒçš„æœ‰æ•ˆé‚®ç®±
- æ¯ä¸ªé‚®ç®±è¯·æä¾›æ¥æºä¿¡æ¯

è¯·ç°åœ¨å¼€å§‹æœç´¢å¹¶å‘Šè¯‰æˆ‘æ‰¾åˆ°çš„çœŸå®é‚®ç®±åœ°å€ã€‚"""

        print(f"ğŸ§  å‘é€æœç´¢æŒ‡ä»¤ç»™Ollama...")
        
        result = self.call_ollama_with_web_search(prompt)
        
        if result['success']:
            print(f"âœ… Ollamaç½‘ç»œæœç´¢å®Œæˆ")
            
            # æ”¶é›†æ‰€æœ‰æ‰¾åˆ°çš„é‚®ç®±
            all_emails = []
            for tool_result in result['tool_results']:
                if tool_result['function_name'] == 'web_search_emails':
                    emails = tool_result['result'].get('emails', [])
                    all_emails.extend(emails)
            
            # å»é‡
            unique_emails = {}
            for email_data in all_emails:
                email = email_data['email']
                if email not in unique_emails:
                    unique_emails[email] = email_data
            
            final_emails = list(unique_emails.values())[:max_emails]
            
            print(f"\nğŸ“§ Ollamaå‘ç°çš„é‚®ç®±:")
            for i, email_data in enumerate(final_emails, 1):
                print(f"   {i}. {email_data['email']} (æ¥æº: {email_data['source']})")
            
            print(f"\nğŸ§  Ollamaåˆ†æ:")
            print(f"   {result['response']}")
            
            return {
                'success': True,
                'emails': [e['email'] for e in final_emails],
                'email_details': final_emails,
                'llm_response': result['response'],
                'total_emails': len(final_emails),
                'search_calls': len(result['tool_calls'])
            }
        else:
            print(f"âŒ Ollamaç½‘ç»œæœç´¢å¤±è´¥: {result['error']}")
            return {
                'success': False,
                'error': result['error'],
                'emails': [],
                'total_emails': 0
            }

def main():
    if len(sys.argv) < 2:
        print(json.dumps({'error': 'è¯·æä¾›è¡Œä¸šåç§° (ä¾‹å¦‚: "AI startup", "fruit companies")'}))
        return
    
    industry = sys.argv[1]
    max_emails = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    
    # åˆå§‹åŒ–ç›´æ¥ç½‘ç»œæœç´¢ç³»ç»Ÿ
    search_system = DirectOllamaWebSearch()
    
    # æ‰§è¡Œé‚®ç®±å‘ç°
    results = search_system.find_emails_with_ollama_web_search(industry, max_emails)
    
    # å‡†å¤‡è¾“å‡º
    output = {
        'success': results['success'],
        'emails': results.get('emails', []),
        'email_details': results.get('email_details', []),
        'total_emails': results.get('total_emails', 0),
        'industry': industry,
        'search_method': 'direct_ollama_web_search',
        'llm_response': results.get('llm_response', ''),
        'search_calls': results.get('search_calls', 0),
        'ollama_web_enabled': True,
        'real_time_search': True,
        'timestamp': datetime.now().isoformat()
    }
    
    print("\n" + "=" * 60)
    print("ğŸ” Direct Ollama Web Search ç»“æœ")
    print("=" * 60)
    
    if results['success']:
        print("ğŸ“§ å‘ç°çš„çœŸå®é‚®ç®±:")
        for email in results['emails']:
            print(f"   ğŸ“§ {email}")
        
        print(f"\nğŸ“Š æœç´¢ç»Ÿè®¡:")
        print(f"   ğŸ“§ é‚®ç®±æ€»æ•°: {results['total_emails']}")
        print(f"   ğŸ” æœç´¢è°ƒç”¨: {results.get('search_calls', 0)}æ¬¡")
        print(f"   ğŸ§  AIå¼•æ“: Ollama (æœ¬åœ°)")
        print(f"   ğŸŒ æœç´¢å¼•æ“: DuckDuckGo + Bing")
        print(f"   âš¡ ç‰¹è‰²: Ollamaç›´æ¥å…·å¤‡è”ç½‘èƒ½åŠ›")
    else:
        print(f"âŒ æœç´¢å¤±è´¥: {results.get('error', 'Unknown error')}")
    
    print(json.dumps(output, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()