#!/usr/bin/env python3
"""
è¶…çº§é‚®ç®±æœç´¢å¼•æ“ - åŸºäº2024å¹´æœ€ä½³å®è·µ
- ä½¿ç”¨æœ€æœ‰æ•ˆçš„Googleæœç´¢æ“ä½œç¬¦
- åŸºäºä¸“ä¸šé‚®ç®±å‘ç°å·¥å…·çš„ç­–ç•¥
- æŒç»­æœç´¢ç›´åˆ°æ‰¾åˆ°çœŸå®é‚®ç®±
- è¯¦ç»†æ—¥å¿—å’Œæ€§èƒ½ç›‘æ§
"""

import sys
import json
import time
import re
import requests
import os
import hashlib
import socket
import dns.resolver
import smtplib
from datetime import datetime
from urllib.parse import quote, urlencode
from bs4 import BeautifulSoup
import concurrent.futures
import logging

class SuperEmailDiscoveryEngine:
    def __init__(self):
        self.setup_logging()

        # SearxNGé…ç½® - Railwayå…¼å®¹
        self.searxng_url = os.environ.get('SEARXNG_URL', 'http://localhost:8080')

        # ç½‘ç»œä¼šè¯é…ç½® - æ— è¶…æ—¶é™åˆ¶
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://www.google.com/',
            'Connection': 'keep-alive'
        })
        # è®¾ç½®æ— é™è¶…æ—¶
        self.session.timeout = None

        # é‚®ç®±æ¨¡å¼
        self.email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')

        # ğŸ”¥ NEW: Email cache directory for deduplication across runs
        self.cache_dir = os.path.join(os.path.dirname(__file__), '.email_cache')
        os.makedirs(self.cache_dir, exist_ok=True)

        # ğŸ”¥ NEW: Domain verification cache (to avoid re-checking same domains)
        self.domain_verification_cache = {}  # domain -> (has_mx, mx_host, is_catch_all)

        # æœç´¢çŠ¶æ€
        self.found_emails = []
        self.already_returned_emails = set()  # ğŸ”¥ NEW: Track already-returned emails
        self.search_stats = {
            'total_queries': 0,
            'successful_queries': 0,
            'emails_found': 0,
            'websites_scraped': 0,
            'unique_domains': set(),
            'query_success_rate': {}
        }

        self.logger.info("ğŸš€ è¶…çº§é‚®ç®±æœç´¢å¼•æ“åˆå§‹åŒ–")
        self.logger.info("   ğŸ“Š åŸºäº2024å¹´æœ€ä½³é‚®ç®±å‘ç°å®è·µ")
        self.logger.info("   ğŸ¯ ç›®æ ‡ï¼šç¡®ä¿æ‰¾åˆ°çœŸå®æœ‰æ•ˆçš„é‚®ç®±åœ°å€")
        self.logger.info("   ğŸ—‚ï¸ ç¼“å­˜ç›®å½•: " + self.cache_dir)
        
    def setup_logging(self):
        """è®¾ç½®è¯¦ç»†æ—¥å¿—"""
        self.logger = logging.getLogger('SuperEmailEngine')
        self.logger.setLevel(logging.INFO)

        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)

        file_handler = logging.FileHandler('super_email_discovery.log', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)

        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%H:%M:%S'
        )

        console_handler.setFormatter(formatter)
        file_handler.setFormatter(formatter)

        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)

    def get_cache_filename(self, industry, session_id=None):
        """ç”Ÿæˆç¼“å­˜æ–‡ä»¶åï¼ˆåŸºäºè¡Œä¸šåç§°å’Œsession IDçš„hashï¼‰"""
        # Create a hash of the industry to use as filename
        industry_hash = hashlib.md5(industry.lower().strip().encode()).hexdigest()[:12]

        # ğŸ”¥ FIX: Use session_id if provided to create campaign-specific cache
        if session_id:
            session_hash = hashlib.md5(str(session_id).encode()).hexdigest()[:8]
            return os.path.join(self.cache_dir, f'returned_emails_{industry_hash}_{session_hash}.txt')
        else:
            return os.path.join(self.cache_dir, f'returned_emails_{industry_hash}.txt')

    def load_returned_emails_cache(self, industry, session_id=None):
        """åŠ è½½å·²è¿”å›çš„é‚®ç®±ç¼“å­˜"""
        cache_file = self.get_cache_filename(industry, session_id)
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_emails = {line.strip() for line in f if line.strip()}
                    self.already_returned_emails = cached_emails
                    session_info = f" (Session: {session_id})" if session_id else ""
                    self.logger.info(f"ğŸ“‚ åŠ è½½ç¼“å­˜: {len(cached_emails)} ä¸ªå·²è¿”å›é‚®ç®± (è¡Œä¸š: {industry}{session_info})")
                    return len(cached_emails)
            except Exception as e:
                self.logger.warning(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
                self.already_returned_emails = set()
        else:
            self.logger.info(f"ğŸ“‚ æ— ç¼“å­˜æ–‡ä»¶ï¼Œå°†è¿”å›å…¨æ–°é‚®ç®±")
            self.already_returned_emails = set()
        return 0

    def save_returned_emails_cache(self, industry, new_emails, session_id=None):
        """ä¿å­˜æ–°è¿”å›çš„é‚®ç®±åˆ°ç¼“å­˜"""
        cache_file = self.get_cache_filename(industry, session_id)
        try:
            # Append new emails to cache file
            with open(cache_file, 'a', encoding='utf-8') as f:
                for email in new_emails:
                    f.write(email + '\n')
                    self.already_returned_emails.add(email)
            self.logger.info(f"ğŸ’¾ ç¼“å­˜å·²æ›´æ–°: +{len(new_emails)} ä¸ªé‚®ç®±")
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def extract_industry_and_audience(self, query):
        """æ™ºèƒ½æå–è¡Œä¸šå’Œç›®æ ‡å—ä¼—å…³é”®è¯"""
        query_lower = query.lower()

        # è¡Œä¸šåˆ†ç±»å…³é”®è¯æ˜ å°„
        industry_keywords = {
            'technology': ['tech', 'software', 'saas', 'it', 'digital', 'cloud', 'ai', 'ml', 'data'],
            'healthcare': ['health', 'medical', 'hospital', 'clinic', 'pharma', 'biotech', 'wellness'],
            'finance': ['finance', 'bank', 'fintech', 'investment', 'insurance', 'accounting'],
            'retail': ['retail', 'store', 'shop', 'merchant', 'ecommerce', 'commerce'],
            'manufacturing': ['manufacturing', 'factory', 'industrial', 'production', 'supply'],
            'food': ['food', 'beverage', 'restaurant', 'culinary', 'nutrition', 'catering'],
            'education': ['education', 'school', 'university', 'training', 'learning', 'academy'],
            'real_estate': ['real estate', 'property', 'housing', 'construction', 'building'],
            'marketing': ['marketing', 'advertising', 'agency', 'branding', 'media'],
            'logistics': ['logistics', 'shipping', 'freight', 'transport', 'delivery', 'warehouse']
        }

        # ç›®æ ‡å—ä¼—å…³é”®è¯æ˜ å°„
        audience_keywords = {
            'buyer': ['buyer', 'purchasing', 'procurement', 'sourcing'],
            'manager': ['manager', 'director', 'head', 'lead', 'supervisor'],
            'executive': ['ceo', 'cto', 'cfo', 'executive', 'president', 'vp', 'chief'],
            'owner': ['owner', 'founder', 'entrepreneur', 'principal'],
            'coordinator': ['coordinator', 'specialist', 'analyst', 'associate'],
            'farmer': ['farmer', 'agriculture', 'farm', 'grower', 'producer'],
            'retailer': ['retailer', 'merchant', 'vendor', 'dealer'],
            'distributor': ['distributor', 'wholesaler', 'supplier'],
            'developer': ['developer', 'engineer', 'programmer', 'architect'],
            'designer': ['designer', 'creative', 'artist', 'ux', 'ui']
        }

        # æ£€æµ‹è¡Œä¸š
        detected_industries = []
        for industry, keywords in industry_keywords.items():
            if any(kw in query_lower for kw in keywords):
                detected_industries.append(industry)

        # æ£€æµ‹ç›®æ ‡å—ä¼—
        detected_audiences = []
        for audience, keywords in audience_keywords.items():
            if any(kw in query_lower for kw in keywords):
                detected_audiences.append(audience)

        return detected_industries, detected_audiences, query

    def generate_professional_search_strategies(self, industry, round_num=1):
        """ç”ŸæˆåŸºäº2024å¹´æœ€ä½³å®è·µçš„ä¸“ä¸šæœç´¢ç­–ç•¥ - å…¨è¡Œä¸šé€šç”¨"""
        self.logger.info(f"ğŸ§  ç”Ÿæˆç¬¬{round_num}è½®ä¸“ä¸šæœç´¢ç­–ç•¥ - {industry}")

        # ğŸ”¥ æ™ºèƒ½æå–è¡Œä¸šå’Œå—ä¼—
        industries, audiences, original_query = self.extract_industry_and_audience(industry)

        self.logger.info(f"   ğŸ¯ æ£€æµ‹åˆ°çš„è¡Œä¸š: {industries if industries else 'é€šç”¨'}")
        self.logger.info(f"   ğŸ‘¥ æ£€æµ‹åˆ°çš„å—ä¼—: {audiences if audiences else 'é€šç”¨'}")

        # åŸºäºç ”ç©¶çš„æœ€æœ‰æ•ˆæœç´¢ç­–ç•¥
        base_strategies = []

        # å¦‚æœæœ‰æ˜ç¡®çš„è¡Œä¸š+å—ä¼—ç»„åˆï¼Œç”Ÿæˆé«˜åº¦é’ˆå¯¹æ€§æœç´¢
        if industries and audiences:
            industry_key = industries[0]
            audience_key = audiences[0]

            if round_num == 1:
                # ç¬¬ä¸€è½®ï¼šæœ€ç²¾å‡†çš„èŒä½+è¡Œä¸šç»„åˆ
                base_strategies = [
                    f'{audience_key} {industry_key} email',
                    f'{industry_key} {audience_key} contact',
                    f'{audience_key} email {industry_key}',
                    f'{industry_key} {audience_key} director email',
                    f'senior {audience_key} {industry_key} contact'
                ]
            elif round_num == 2:
                # ç¬¬äºŒè½®ï¼šç»„ç»‡å±‚çº§æœç´¢
                base_strategies = [
                    f'{industry_key} {audience_key} team email',
                    f'{audience_key} department {industry_key} contact',
                    f'{industry_key} {audience_key} lead email',
                    f'{audience_key} {industry_key} head contact',
                    f'{industry_key} {audience_key} manager email'
                ]
            elif round_num == 3:
                # ç¬¬ä¸‰è½®ï¼šåœ°åŸŸ+èŒä½æœç´¢
                base_strategies = [
                    f'{audience_key} {industry_key} USA email',
                    f'{industry_key} {audience_key} North America contact',
                    f'{audience_key} {industry_key} regional email',
                    f'{industry_key} {audience_key} national contact',
                    f'{audience_key} {industry_key} local email'
                ]
            else:
                # å…¶ä»–è½®æ¬¡ï¼šå¤šç§ç»„åˆ
                base_strategies = [
                    f'{industry_key} {audience_key} professional email',
                    f'{audience_key} {industry_key} company contact',
                    f'{industry_key} {audience_key} business email',
                    f'{audience_key} role {industry_key} contact',
                    f'{industry_key} {audience_key} executive email'
                ]

        # åªæœ‰è¡Œä¸šï¼Œæ²¡æœ‰æ˜ç¡®å—ä¼—
        elif industries:
            industry_key = industries[0]

            if round_num == 1:
                base_strategies = [
                    f'{industry_key} buyer email',
                    f'{industry_key} manager contact',
                    f'{industry_key} director email',
                    f'{industry_key} CEO contact',
                    f'{industry_key} executive email'
                ]
            elif round_num == 2:
                base_strategies = [
                    f'{industry_key} owner email',
                    f'{industry_key} founder contact',
                    f'{industry_key} partner email',
                    f'{industry_key} president contact',
                    f'{industry_key} VP email'
                ]
            elif round_num == 3:
                base_strategies = [
                    f'{industry_key} sales email',
                    f'{industry_key} marketing contact',
                    f'{industry_key} operations email',
                    f'{industry_key} procurement contact',
                    f'{industry_key} purchasing email'
                ]
            else:
                base_strategies = [
                    f'{industry_key} team email',
                    f'{industry_key} department contact',
                    f'{industry_key} specialist email',
                    f'{industry_key} coordinator contact',
                    f'{industry_key} analyst email'
                ]

        # åªæœ‰å—ä¼—ï¼Œæ²¡æœ‰æ˜ç¡®è¡Œä¸š
        elif audiences:
            audience_key = audiences[0]

            if round_num == 1:
                base_strategies = [
                    f'{audience_key} business email',
                    f'{audience_key} company contact',
                    f'{audience_key} corporate email',
                    f'{audience_key} enterprise contact',
                    f'{audience_key} professional email'
                ]
            elif round_num == 2:
                base_strategies = [
                    f'{audience_key} startup email',
                    f'{audience_key} SMB contact',
                    f'{audience_key} small business email',
                    f'{audience_key} mid-market contact',
                    f'{audience_key} organization email'
                ]
            else:
                base_strategies = [
                    f'{audience_key} consultant email',
                    f'{audience_key} advisor contact',
                    f'{audience_key} specialist email',
                    f'{audience_key} expert contact',
                    f'{audience_key} services email'
                ]

        # é€šç”¨æœç´¢ï¼ˆæ²¡æœ‰æ£€æµ‹åˆ°è¡Œä¸šæˆ–å—ä¼—ï¼‰
        else:
            if round_num == 1:
                base_strategies = [
                    f'{industry} email contact',
                    f'{industry} CEO email',
                    f'{industry} founder contact',
                    f'{industry} business email',
                    f'{industry} company contact'
                ]
            elif round_num == 2:
                base_strategies = [
                    f'{industry} team email',
                    f'{industry} sales contact',
                    f'{industry} support email',
                    f'{industry} info contact',
                    f'{industry} director email'
                ]
            elif round_num == 3:
                base_strategies = [
                    f'{industry} manager email',
                    f'{industry} consultant contact',
                    f'{industry} specialist email',
                    f'{industry} expert contact',
                    f'{industry} advisor email'
                ]
            elif round_num == 4:
                base_strategies = [
                    f'{industry} startup email',
                    f'{industry} entrepreneur contact',
                    f'{industry} business owner email',
                    f'{industry} partner contact',
                    f'{industry} investor email'
                ]
            elif round_num == 5:
                base_strategies = [
                    f'{industry} marketing email',
                    f'{industry} operations contact',
                    f'{industry} product manager email',
                    f'{industry} customer success contact',
                    f'{industry} growth email'
                ]
            elif round_num % 3 == 0:
                base_strategies = [
                    f'{industry} North America email',
                    f'{industry} Europe contact',
                    f'{industry} Asia Pacific email',
                    f'{industry} global contact',
                    f'{industry} international email'
                ]
            elif round_num % 3 == 1:
                base_strategies = [
                    f'{industry} CTO email',
                    f'{industry} developer contact',
                    f'{industry} engineer email',
                    f'{industry} architect contact',
                    f'{industry} technical lead email'
                ]
            else:
                base_strategies = [
                    f'{industry} company email',
                    f'{industry} business contact',
                    f'{industry} executive email',
                    f'{industry} leadership contact',
                    f'{industry} decision maker email'
                ]
        
        self.logger.info(f"   âœ… ç”Ÿæˆ{len(base_strategies)}ä¸ªä¸“ä¸šçº§æœç´¢ç­–ç•¥")
        return base_strategies
    
    def search_with_advanced_logging(self, query, max_results=50):
        """é«˜çº§SearxNGæœç´¢ - æ— è¶…æ—¶é™åˆ¶ï¼Œå°½å¯èƒ½å¤šåœ°è·å–ç»“æœ"""
        try:
            self.logger.info(f"ğŸ” æ·±åº¦ä¸“ä¸šæœç´¢: {query[:80]}...")
            self.search_stats['total_queries'] += 1
            
            params = {
                'q': query,
                'format': 'json',
                'categories': 'general',
                'pageno': 1
            }
            
            start_time = time.time()
            # ç§»é™¤è¶…æ—¶é™åˆ¶ - è®©æœç´¢æœ‰è¶³å¤Ÿæ—¶é—´å®Œæˆ
            response = self.session.get(f"{self.searxng_url}/search", params=params)
            duration = time.time() - start_time
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    results = data.get('results', [])
                    
                    self.logger.info(f"   âœ… æœç´¢æˆåŠŸ ({duration:.1f}s): {len(results)}ä¸ªç»“æœ")
                    self.search_stats['successful_queries'] += 1
                    
                    # åˆ†æç»“æœè´¨é‡
                    email_indicators = 0
                    contact_indicators = 0
                    
                    for result in results:
                        text = f"{result.get('title', '')} {result.get('content', '')}".lower()
                        if '@' in text:
                            email_indicators += 1
                        if any(word in text for word in ['contact', 'email', 'reach']):
                            contact_indicators += 1
                    
                    self.logger.info(f"   ğŸ“Š è´¨é‡åˆ†æ: {email_indicators}ä¸ª@ç¬¦å·, {contact_indicators}ä¸ªè”ç³»æŒ‡ç¤ºå™¨")
                    
                    # è®°å½•æŸ¥è¯¢æˆåŠŸç‡
                    query_type = self.classify_query_type(query)
                    if query_type not in self.search_stats['query_success_rate']:
                        self.search_stats['query_success_rate'][query_type] = {'success': 0, 'total': 0}
                    
                    self.search_stats['query_success_rate'][query_type]['total'] += 1
                    if email_indicators > 0:
                        self.search_stats['query_success_rate'][query_type]['success'] += 1
                    
                    return results[:max_results]
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"   âŒ JSONè§£æå¤±è´¥: {str(e)}")
                    return []
            else:
                self.logger.error(f"   âŒ æœç´¢è¯·æ±‚å¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            self.logger.error(f"   âŒ æœç´¢é”™è¯¯: {str(e)}")
            return []
    
    def classify_query_type(self, query):
        """åˆ†ç±»æœç´¢æŸ¥è¯¢ç±»å‹ä»¥è¿›è¡Œæ€§èƒ½åˆ†æ"""
        query_lower = query.lower()
        if 'site:linkedin.com' in query_lower:
            return 'linkedin_search'
        elif 'site:' in query_lower:
            return 'site_specific'
        elif 'filetype:' in query_lower:
            return 'file_search'
        elif 'intext:' in query_lower:
            return 'content_search'
        else:
            return 'general_search'
    
    def is_personal_email(self, email):
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸ªäººé‚®ç®±ï¼ˆéé€šç”¨é‚®ç®±ï¼‰"""
        generic_prefixes = [
            'info', 'contact', 'hello', 'hi', 'support', 'help', 'admin',
            'sales', 'marketing', 'office', 'general', 'inquiry', 'service',
            'careers', 'jobs', 'hr', 'feedback', 'team', 'press', 'media',
            'noreply', 'no-reply', 'webmaster', 'postmaster'
        ]

        username = email.split('@')[0].lower()

        # é€šç”¨é‚®ç®±åˆ¤æ–­
        if any(username.startswith(prefix) for prefix in generic_prefixes):
            return False
        if any(username == prefix for prefix in generic_prefixes):
            return False

        # ä¸ªäººé‚®ç®±é€šå¸¸åŒ…å«åå­—ï¼ˆæœ‰ç‚¹ã€ä¸‹åˆ’çº¿æˆ–é©¼å³°å‘½åï¼‰
        if '.' in username or '_' in username:
            return True
        if any(c.isupper() for c in email.split('@')[0]):  # é©¼å³°å‘½å
            return True

        # åå­—é•¿åº¦åˆ¤æ–­ï¼ˆä¸ªäººé‚®ç®±é€šå¸¸5-20å­—ç¬¦ï¼‰
        if 5 <= len(username) <= 20 and username.isalpha():
            return True

        return False

    def extract_context_around_email(self, html_content, email):
        """æå–é‚®ç®±å‘¨å›´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå§“åã€èŒä½ã€éƒ¨é—¨ï¼‰"""
        if not html_content or not email:
            return {}

        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')

            # æŸ¥æ‰¾åŒ…å«æ­¤é‚®ç®±çš„å…ƒç´ 
            email_elements = soup.find_all(string=re.compile(re.escape(email)))

            context = {
                'name': None,
                'title': None,
                'department': None
            }

            # èŒä½å…³é”®è¯
            title_keywords = [
                'CEO', 'CTO', 'CFO', 'COO', 'President', 'Vice President', 'VP',
                'Director', 'Manager', 'Head', 'Lead', 'Chief', 'Founder',
                'Engineer', 'Developer', 'Scientist', 'Researcher', 'Analyst',
                'Coordinator', 'Specialist', 'Consultant', 'Advisor'
            ]

            # éƒ¨é—¨å…³é”®è¯
            dept_keywords = [
                'Engineering', 'Marketing', 'Sales', 'Finance', 'HR',
                'Human Resources', 'Operations', 'IT', 'Technology', 'Product',
                'Research', 'Development', 'Customer Success', 'Support',
                'Food Science', 'Nutrition', 'Culinary', 'Agriculture'
            ]

            for elem in email_elements:
                parent = elem.parent
                if not parent:
                    continue

                # è·å–çˆ¶å…ƒç´ åŠå…¶å‘¨å›´çš„æ–‡æœ¬
                context_text = parent.get_text(separator=' ', strip=True)

                # æ‰©å±•åˆ°æ›´å¤§çš„ä¸Šä¸‹æ–‡ï¼ˆç¥–çˆ¶å…ƒç´ ï¼‰
                if parent.parent:
                    context_text += ' ' + parent.parent.get_text(separator=' ', strip=True)

                # æå–èŒä½
                for title_kw in title_keywords:
                    if title_kw.lower() in context_text.lower():
                        context['title'] = title_kw
                        break

                # æå–éƒ¨é—¨
                for dept_kw in dept_keywords:
                    if dept_kw.lower() in context_text.lower():
                        context['department'] = dept_kw
                        break

                # å°è¯•æå–å§“åï¼ˆé‚®ç®±é™„è¿‘çš„å¤§å†™å•è¯æ¨¡å¼ï¼‰
                # åŒ¹é… "John Smith" æˆ– "Dr. John Smith" ç­‰æ¨¡å¼
                name_pattern = r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)+)\b'
                names = re.findall(name_pattern, context_text)
                if names and not context['name']:
                    # è¿‡æ»¤æ‰å…¬å¸åã€èŒä½åç­‰
                    for name in names:
                        name_lower = name.lower()
                        # æ’é™¤èŒä½å…³é”®è¯
                        if not any(kw.lower() in name_lower for kw in title_keywords):
                            # æ’é™¤éƒ¨é—¨å…³é”®è¯
                            if not any(kw.lower() in name_lower for kw in dept_keywords):
                                context['name'] = name
                                break

                # å¦‚æœæ‰¾åˆ°äº†æœ‰ç”¨ä¿¡æ¯ï¼Œæå‰ç»“æŸ
                if context['name'] or context['title'] or context['department']:
                    break

            return context

        except Exception as e:
            self.logger.debug(f"   âš ï¸ ä¸Šä¸‹æ–‡æå–å¤±è´¥: {e}")
            return {}

    def extract_emails_advanced(self, text, source="", html_content=None):
        """é«˜çº§é‚®ç®±æå– - ä½¿ç”¨2024å¹´æœ€ä½³æ¨¡å¼ + ä¼˜å…ˆä¸ªäººé‚®ç®±"""
        if not text:
            return []

        # æ‰¾åˆ°æ‰€æœ‰æ½œåœ¨é‚®ç®±
        potential_emails = self.email_pattern.findall(text)

        valid_emails = []
        excluded_count = 0

        for email in potential_emails:
            email_lower = email.lower()

            # 2024å¹´æ›´æ–°çš„æ’é™¤è§„åˆ™
            exclusions = [
                'example.com', 'test.com', 'domain.com', 'yoursite.com', 'company.com',
                'noreply', 'no-reply', 'donotreply', 'bounce', 'mailer-daemon',
                'privacy@', 'legal@', 'abuse@', 'postmaster@', 'webmaster@',
                'support@example', 'admin@example', 'info@example', 'sales@example',
                'sample@', 'demo@', 'fake@', 'null@', 'void@', 'placeholder@',
                'youremail@', 'your-email@', 'email@', 'mailto:',
            ]

            if any(pattern in email_lower for pattern in exclusions):
                excluded_count += 1
                continue

            # ğŸ”¥ NEW: Check for suspicious patterns (phone numbers in email addresses)
            # Pattern: xxx-xxx-xxxx or similar (indicates likely invalid email)
            if re.search(r'\d{3}[-.]?\d{3}[-.]?\d{4}', email):
                self.logger.debug(f"   ğŸš« å¯ç–‘ç”µè¯å·ç æ¨¡å¼: {email}")
                excluded_count += 1
                continue

            # ğŸ”¥ NEW: Check local part length (too long = suspicious)
            local_part = email.split('@')[0]
            if len(local_part) > 40:  # Abnormally long local part
                self.logger.debug(f"   ğŸš« æœ¬åœ°éƒ¨åˆ†è¿‡é•¿: {email}")
                excluded_count += 1
                continue

            # æ­¥éª¤1ï¼šéªŒè¯é‚®ç®±æ ¼å¼
            if not self.validate_email_format(email):
                excluded_count += 1
                continue

            # ğŸ”¥ NEW æ­¥éª¤2ï¼šè¿‡æ»¤é€šç”¨/éƒ¨é—¨é‚®ç®±ï¼Œåªä¿ç•™ä¸“ä¸šå†³ç­–è€…é‚®ç®±
            is_prof, prof_reason = self.is_professional_email(email)
            if not is_prof:
                self.logger.info(f"   â›” è¿‡æ»¤éä¸“ä¸šé‚®ç®±: {email} (åŸå› : {prof_reason})")
                excluded_count += 1
                continue

            # æ­¥éª¤3ï¼šç»¼åˆéªŒè¯é‚®ç®±å¯æŠ•é€’æ€§ï¼ˆDNS MX + SMTPï¼‰
            is_deliverable, verification_info = self.verify_email_deliverability(email)
            if not is_deliverable:
                self.logger.warning(f"   âŒ é‚®ç®±éªŒè¯å¤±è´¥: {email} - {verification_info.get('reason')}")
                excluded_count += 1
                continue

            # æå–é‚®ç®±å‘¨å›´çš„ä¸Šä¸‹æ–‡ï¼ˆå§“åã€èŒä½ã€éƒ¨é—¨ï¼‰
            context = self.extract_context_around_email(html_content, email) if html_content else {}

            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºéªŒè¯çŠ¶æ€ï¼‰
            base_confidence = 0.9 if self.is_personal_email(email) else 0.7
            if verification_info.get('status') == 'catch_all':
                base_confidence += verification_info.get('confidence_penalty', -0.2)
            elif verification_info.get('status') == 'unverifiable':
                base_confidence -= 0.1

            valid_emails.append({
                'email': email,
                'is_personal': self.is_personal_email(email),
                'name': context.get('name'),
                'title': context.get('title'),
                'department': context.get('department'),
                'verification': verification_info,
                'confidence': base_confidence
            })

            domain = email.split('@')[1]
            self.search_stats['unique_domains'].add(domain)

            email_type = "ä¸ªäºº" if self.is_personal_email(email) else "é€šç”¨"
            verification_status = verification_info.get('status', 'unknown')
            self.logger.info(f"   âœ… å‘ç°{email_type}é‚®ç®±: {email} [éªŒè¯: {verification_status}] (æ¥æº: {source[:30]})")
            if context.get('name'):
                self.logger.info(f"      ğŸ‘¤ å§“å: {context['name']}")
            if context.get('title'):
                self.logger.info(f"      ğŸ’¼ èŒä½: {context['title']}")
            if context.get('department'):
                self.logger.info(f"      ğŸ¢ éƒ¨é—¨: {context['department']}")

        if excluded_count > 0:
            self.logger.debug(f"   ğŸ—‘ï¸ æ’é™¤äº†{excluded_count}ä¸ªç¤ºä¾‹/æ— æ•ˆé‚®ç®±")

        # ä¼˜å…ˆè¿”å›ä¸ªäººé‚®ç®±
        personal_emails = [e for e in valid_emails if e['is_personal']]
        generic_emails = [e for e in valid_emails if not e['is_personal']]

        # ä¸ªäººé‚®ç®± + é€šç”¨é‚®ç®±ï¼ˆæœ‰ä¸Šä¸‹æ–‡çš„ä¼˜å…ˆï¼‰
        generic_with_context = [e for e in generic_emails if e.get('name') or e.get('title') or e.get('department')]
        generic_without_context = [e for e in generic_emails if not (e.get('name') or e.get('title') or e.get('department'))]

        prioritized_emails = personal_emails + generic_with_context + generic_without_context

        self.logger.info(f"   ğŸ“Š é‚®ç®±åˆ†ç±»: {len(personal_emails)}ä¸ªäºº + {len(generic_with_context)}é€šç”¨(æœ‰ä¸Šä¸‹æ–‡) + {len(generic_without_context)}é€šç”¨(æ— ä¸Šä¸‹æ–‡)")

        return prioritized_emails
    
    def validate_email_format(self, email):
        """éªŒè¯é‚®ç®±æ ¼å¼"""
        if not (5 < len(email) < 100 and email.count('@') == 1):
            return False

        local, domain = email.split('@')

        # æ£€æŸ¥æœ¬åœ°éƒ¨åˆ†
        if not local or len(local) > 64:
            return False

        # æ£€æŸ¥åŸŸåéƒ¨åˆ†
        if not domain or '.' not in domain or len(domain) < 4:
            return False

        # æ£€æŸ¥é¡¶çº§åŸŸå
        tld = domain.split('.')[-1]
        if len(tld) < 2 or not tld.isalpha():
            return False

        return True

    def is_professional_email(self, email):
        """
        Check if email is from a professional/decision-maker, not generic department email
        Returns: (is_professional, reason)
        """
        email_lower = email.lower()
        local_part = email_lower.split('@')[0]

        # Generic/department email patterns to REJECT
        generic_patterns = [
            'info', 'support', 'help', 'contact', 'admin', 'webmaster',
            'sales', 'marketing', 'hr', 'media', 'press', 'news',
            'customer', 'service', 'hello', 'team', 'general',
            'inquiry', 'enquiry', 'reception', 'office',
            'noreply', 'no-reply', 'donotreply',
            'abuse', 'postmaster', 'hostmaster',
            'careers', 'jobs', 'recruiting',
            'billing', 'accounts', 'finance',
            'legal', 'compliance', 'privacy',
            'customersupport', 'techsupport', 'itsupport'
        ]

        # Check if local part is exactly a generic pattern
        if local_part in generic_patterns:
            return False, f"generic_exact:{local_part}"

        # Check if local part starts with generic pattern
        for pattern in generic_patterns:
            if local_part.startswith(pattern + '.') or local_part.startswith(pattern + '-') or local_part.startswith(pattern + '_'):
                return False, f"generic_prefix:{pattern}"

        # Academic/EDU emails - be more selective
        domain = email_lower.split('@')[1]
        if domain.endswith('.edu') or domain.endswith('.ac.uk'):
            # Allow individual names like firstname.lastname@, but reject department emails
            if any(gen in local_part for gen in ['president', 'admin', 'it', 'help', 'media', 'office']):
                return False, "edu_department"
            # Require at least a dot or number (indicating personal email)
            if '.' not in local_part and not any(c.isdigit() for c in local_part):
                return False, "edu_no_personal_indicator"

        # Government emails - usually not B2B targets
        if domain.endswith('.gov'):
            return False, "government_email"

        # Must have personal indicators (firstname.lastname pattern is ideal)
        has_dot = '.' in local_part
        has_underscore = '_' in local_part
        has_number = any(c.isdigit() for c in local_part)

        # Ideal: firstname.lastname format
        if has_dot and len(local_part.split('.')) >= 2:
            parts = local_part.split('.')
            if all(len(p) >= 2 for p in parts):  # Each part at least 2 chars
                return True, "firstname_lastname_format"

        # Good: has personal indicators
        if has_dot or has_underscore or has_number:
            return True, "has_personal_indicator"

        # Acceptable: single word but at least 4 chars (could be name)
        if len(local_part) >= 4 and local_part.isalpha():
            return True, "single_name_acceptable"

        # Reject: too short or suspicious
        return False, "no_personal_indicator"

    def verify_mx_records(self, domain):
        """éªŒè¯åŸŸåæ˜¯å¦æœ‰æœ‰æ•ˆçš„MXè®°å½•"""
        try:
            mx_records = dns.resolver.resolve(domain, 'MX')
            mx_hosts = [str(r.exchange).rstrip('.') for r in mx_records]
            if mx_hosts:
                self.logger.debug(f"   âœ… MXè®°å½•å­˜åœ¨: {domain} -> {mx_hosts[0]}")
                return True, mx_hosts[0]
            return False, None
        except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers):
            self.logger.warning(f"   âŒ æ— MXè®°å½•: {domain}")
            return False, None
        except Exception as e:
            self.logger.debug(f"   âš ï¸ MXæŸ¥è¯¢å¤±è´¥: {domain} - {str(e)}")
            return False, None

    def verify_email_smtp(self, email, mx_host):
        """ä½¿ç”¨SMTPéªŒè¯é‚®ç®±æ˜¯å¦å­˜åœ¨ï¼ˆæ— éœ€å‘é€é‚®ä»¶ï¼‰"""
        try:
            # è®¾ç½®è¶…æ—¶
            smtp = smtplib.SMTP(timeout=15)
            smtp.set_debuglevel(0)  # ç¦ç”¨è°ƒè¯•è¾“å‡º
            smtp.connect(mx_host, 25)

            # ä½¿ç”¨æ›´å¯ä¿¡çš„HELOåŸŸå
            smtp.helo(socket.getfqdn())

            # ä½¿ç”¨æ›´å¯ä¿¡çš„å‘ä»¶äººåœ°å€
            smtp.mail('postmaster@' + socket.getfqdn())

            code, message = smtp.rcpt(email)
            smtp.quit()

            # SMTPå“åº”ç ï¼š
            # 250 = é‚®ç®±å­˜åœ¨
            # 550 = é‚®ç®±ä¸å­˜åœ¨ï¼ˆæ˜ç¡®æ‹’ç»ï¼‰
            # 551 = ç”¨æˆ·ä¸åœ¨æ­¤æœåŠ¡å™¨
            # 553 = é‚®ç®±åç§°ä¸å…è®¸
            # 450/451/452 = æš‚æ—¶æ— æ³•éªŒè¯
            if code == 250:
                self.logger.debug(f"   âœ… SMTPéªŒè¯é€šè¿‡: {email}")
                return True, "valid"
            elif code in [450, 451, 452]:
                self.logger.debug(f"   âš ï¸ SMTPæš‚æ—¶æ— æ³•éªŒè¯: {email} (code: {code})")
                return True, "unverifiable"
            elif code in [550, 551, 553]:
                self.logger.warning(f"   âŒ SMTPæ˜ç¡®æ‹’ç»: {email} (code: {code})")
                return False, "invalid"
            else:
                self.logger.debug(f"   âš ï¸ SMTPæœªçŸ¥å“åº”: {email} (code: {code})")
                return True, "unverifiable"
        except smtplib.SMTPServerDisconnected:
            self.logger.debug(f"   âš ï¸ SMTPæœåŠ¡å™¨æ–­å¼€: {email}")
            return True, "unverifiable"
        except smtplib.SMTPConnectError as e:
            self.logger.debug(f"   âš ï¸ SMTPè¿æ¥å¤±è´¥: {email} - {str(e)}")
            return True, "unverifiable"
        except socket.timeout:
            self.logger.debug(f"   âš ï¸ SMTPè¶…æ—¶: {email}")
            return True, "unverifiable"
        except Exception as e:
            self.logger.debug(f"   âš ï¸ SMTPéªŒè¯å¼‚å¸¸: {email} - {str(e)}")
            return True, "unverifiable"

    def is_catch_all_domain(self, domain, mx_host):
        """æ£€æµ‹åŸŸåæ˜¯å¦ä¸ºcatch-allï¼ˆæ¥å—æ‰€æœ‰é‚®ç®±åœ°å€ï¼‰"""
        try:
            # æµ‹è¯•ä¸€ä¸ªè‚¯å®šä¸å­˜åœ¨çš„éšæœºé‚®ç®±
            random_email = f"nonexistent{int(time.time())}@{domain}"
            smtp = smtplib.SMTP(timeout=10)
            smtp.connect(mx_host)
            smtp.helo('verification-bot.com')
            smtp.mail('verify@verification-bot.com')
            code, message = smtp.rcpt(random_email)
            smtp.quit()

            if code == 250:
                self.logger.info(f"   ğŸ” æ£€æµ‹åˆ°catch-allåŸŸå: {domain}")
                return True
            return False
        except Exception as e:
            self.logger.debug(f"   âš ï¸ Catch-allæ£€æµ‹å¤±è´¥: {domain} - {str(e)}")
            return False  # æ— æ³•ç¡®å®šæ—¶ï¼Œä¿å®ˆå¤„ç†

    def verify_email_deliverability(self, email):
        """ç»¼åˆéªŒè¯é‚®ç®±å¯æŠ•é€’æ€§ï¼šæ ¼å¼+DNS MX+SMTPï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # æ­¥éª¤1ï¼šåŸºæœ¬æ ¼å¼éªŒè¯
        if not self.validate_email_format(email):
            self.logger.debug(f"   âŒ æ ¼å¼æ— æ•ˆ: {email}")
            return False, {"reason": "invalid_format"}

        domain = email.split('@')[1]

        # æ­¥éª¤2ï¼šæ£€æŸ¥åŸŸåç¼“å­˜
        if domain in self.domain_verification_cache:
            cache = self.domain_verification_cache[domain]
            has_mx, mx_host, is_catch_all = cache
            self.logger.debug(f"   ğŸ“¦ ä½¿ç”¨ç¼“å­˜: {domain} (MX: {has_mx}, Catch-all: {is_catch_all})")
        else:
            # DNS MXè®°å½•éªŒè¯
            has_mx, mx_host = self.verify_mx_records(domain)
            if not has_mx:
                self.logger.debug(f"   âŒ æ— MXè®°å½•: {email}")
                self.domain_verification_cache[domain] = (False, None, False)
                return False, {"reason": "no_mx_record", "domain": domain}

            # æ£€æµ‹catch-allåŸŸå
            is_catch_all = self.is_catch_all_domain(domain, mx_host)

            # ç¼“å­˜åŸŸåéªŒè¯ç»“æœ
            self.domain_verification_cache[domain] = (has_mx, mx_host, is_catch_all)

        # æ­¥éª¤3ï¼šSMTPéªŒè¯ï¼ˆå¦‚æœä¸æ˜¯catch-allï¼‰
        if not is_catch_all:
            is_valid, status = self.verify_email_smtp(email, mx_host)
            if not is_valid:
                self.logger.debug(f"   âŒ SMTPéªŒè¯å¤±è´¥: {email}")
                return False, {"reason": "smtp_rejected", "status": status}

            self.logger.info(f"   âœ… é‚®ç®±éªŒè¯é€šè¿‡: {email} (status: {status})")
            return True, {"status": status, "mx_host": mx_host}
        else:
            # Catch-allåŸŸåï¼šæ¥å—ä½†æ ‡è®°ä½ç½®ä¿¡åº¦
            self.logger.info(f"   âš ï¸ Catch-allåŸŸå: {email} (ä½ç½®ä¿¡åº¦)")
            return True, {"status": "catch_all", "mx_host": mx_host, "confidence_penalty": -0.2}
    
    def scrape_website_advanced(self, url):
        """é«˜çº§ç½‘ç«™çˆ¬å– - ä¸“æ³¨è”ç³»ä¿¡æ¯ï¼Œæ— æ—¶é—´é™åˆ¶ + ä¸Šä¸‹æ–‡æå–"""
        try:
            self.logger.info(f"   ğŸŒ æ·±åº¦æ— é™çˆ¬å–: {url[:60]}...")
            self.search_stats['websites_scraped'] += 1

            start_time = time.time()
            # ç§»é™¤è¶…æ—¶é™åˆ¶ - è®©çˆ¬å–æœ‰å……è¶³æ—¶é—´
            response = self.session.get(url)
            duration = time.time() - start_time

            if response.status_code != 200:
                self.logger.warning(f"   âš ï¸ HTTP {response.status_code}: {url}")
                return []

            soup = BeautifulSoup(response.content, 'html.parser')

            # ä¿å­˜åŸå§‹HTMLç”¨äºä¸Šä¸‹æ–‡æå–
            html_content = response.content

            # ç§»é™¤å¹²æ‰°å…ƒç´ 
            for element in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):
                element.decompose()

            # ä¼˜å…ˆæœç´¢è”ç³»ç›¸å…³åŒºåŸŸ
            priority_areas = []

            # æŸ¥æ‰¾è”ç³»é¡µé¢å…³é”®åŒºåŸŸ
            contact_selectors = [
                '[class*="contact"]', '[id*="contact"]',
                '[class*="about"]', '[id*="about"]',
                '[class*="team"]', '[id*="team"]',
                '[class*="staff"]', '[id*="staff"]',
                '[class*="press"]', '[id*="press"]',
                '[class*="media"]', '[id*="media"]'
            ]

            for selector in contact_selectors:
                elements = soup.select(selector)
                for elem in elements:
                    priority_areas.append(elem.get_text())

            # è·å–ä¸»è¦å†…å®¹
            main_content = soup.get_text()

            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼Œä¼˜å…ˆå¤„ç†è”ç³»åŒºåŸŸ
            all_text = ' '.join(priority_areas) + ' ' + main_content

            # ä¼ é€’HTMLå†…å®¹ä»¥æå–ä¸Šä¸‹æ–‡
            emails = self.extract_emails_advanced(all_text, f"ç½‘ç«™ {url}", html_content)

            self.logger.info(f"   âœ… çˆ¬å–å®Œæˆ ({duration:.1f}s): {len(emails)}ä¸ªé‚®ç®±")
            return emails

        except Exception as e:
            self.logger.error(f"   âŒ çˆ¬å–å¤±è´¥ {url}: {str(e)}")
            return []
    
    def execute_persistent_discovery(self, industry, target_count=5, max_rounds=None, session_id=None):
        """æ‰§è¡Œæ— é™åˆ¶æŒç»­æœç´¢ - è¶Šå¤šè¶Šå‡†ç¡®"""
        # ğŸ”¥ FIX: Scale max_rounds based on target_count
        # Each round finds ~5-15 new emails on average (after filtering cached)
        # Use at least 100 rounds, scale up for larger requests, cap at 500 for safety
        if max_rounds is None:
            max_rounds = min(500, max(100, target_count // 5))  # ~5 emails per round, max 500 rounds

        self.logger.info(f"ğŸš€ å¯åŠ¨æ— é™åˆ¶è¶…çº§é‚®ç®±æœç´¢ - {industry}")
        self.logger.info(f"   ğŸ¯ ç›®æ ‡: {target_count}ä¸ªNEWé‚®ç®± (è·³è¿‡å·²è¿”å›)")
        self.logger.info(f"   ğŸ”„ æœ€å¤§è½®æ•°: {max_rounds} (åŠ¨æ€è°ƒæ•´ï¼Œç¡®ä¿æ‰¾åˆ°è¶³å¤Ÿæ–°é‚®ç®±)")
        self.logger.info(f"   ğŸ“Š ä½¿ç”¨2024å¹´æœ€ä½³æœç´¢å®è·µ")
        self.logger.info(f"   â° æ— æ—¶é—´é™åˆ¶ - æŒç»­æœç´¢ç›´åˆ°æ‰¾åˆ°è¶³å¤Ÿæ–°é‚®ç®±")
        if session_id:
            self.logger.info(f"   ğŸ”‘ Session ID: {session_id} (campaign-specific cache)")

        # ğŸ”¥ FIX: Load cache of already-returned emails with session_id
        cached_count = self.load_returned_emails_cache(industry, session_id)
        if cached_count > 0:
            self.logger.info(f"   ğŸ”„ è·³è¿‡å·²è¿”å›çš„ {cached_count} ä¸ªé‚®ç®±ï¼Œå¯»æ‰¾æ–°é‚®ç®±...")

        start_time = time.time()
        all_emails = []
        round_num = 1
        consecutive_empty_rounds = 0
        total_emails_found = 0  # ğŸ”¥ FIX: Track total including duplicates
        total_cached_skipped = 0  # ğŸ”¥ FIX: Track how many cached emails skipped
        
        while len(all_emails) < target_count and round_num <= max_rounds:
            self.logger.info(f"\nğŸ“ ç¬¬{round_num}è½®æœç´¢ (å·²æ‰¾åˆ° {len(all_emails)}/{target_count})")
            
            # ç”Ÿæˆæœ¬è½®ç­–ç•¥
            strategies = self.generate_professional_search_strategies(industry, round_num)
            round_emails = []
            
            for i, strategy in enumerate(strategies, 1):
                self.logger.info(f"   ğŸ¯ ç­–ç•¥{i}/{len(strategies)}: {strategy[:70]}...")
                
                
                # æœç´¢
                results = self.search_with_advanced_logging(strategy)
                
                if not results:
                    self.logger.warning(f"   âš ï¸ ç­–ç•¥{i} æ— ç»“æœ")
                    continue
                
                # ä»æœç´¢é¢„è§ˆæå–é‚®ç®±
                preview_emails = []
                for result in results:
                    text = f"{result.get('title', '')} {result.get('content', '')}"
                    emails = self.extract_emails_advanced(text, f"æœç´¢é¢„è§ˆ {i}")

                    for email_data in emails:
                        total_emails_found += 1  # ğŸ”¥ FIX: Count all emails found
                        email_addr = email_data['email']
                        # ğŸ”¥ NEW: Skip already-returned emails
                        if email_addr in self.already_returned_emails:
                            total_cached_skipped += 1  # ğŸ”¥ FIX: Track skipped
                            continue
                        if not any(e['email'] == email_addr for e in preview_emails):
                            preview_emails.append({
                                'email': email_addr,
                                'name': email_data.get('name'),
                                'title': email_data.get('title'),
                                'department': email_data.get('department'),
                                'is_personal': email_data.get('is_personal', False),
                                'source': 'search_preview',
                                'source_url': result.get('url', ''),
                                'source_title': result.get('title', ''),
                                'confidence': 0.9 if email_data.get('is_personal') else 0.7,
                                'round': round_num,
                                'strategy': strategy,
                                'discovery_method': 'professional_search'
                            })
                
                round_emails.extend(preview_emails)
                self.logger.info(f"   ğŸ“§ ç­–ç•¥{i}é¢„è§ˆ: {len(preview_emails)}ä¸ªé‚®ç®±")
                
                # å¹¶è¡Œçˆ¬å–æ›´å¤šç½‘ç«™ - æ— é™åˆ¶æ¨¡å¼
                promising_sites = [r for r in results[:20] 
                                 if any(word in r.get('url', '').lower() 
                                       for word in ['contact', 'about', 'team', 'press'])]
                
                if not promising_sites:
                    promising_sites = results[:15]  # å¢åŠ å¤‡é€‰æ–¹æ¡ˆæ•°é‡
                
                self.logger.info(f"   ğŸŒ æ·±åº¦å¹¶è¡Œçˆ¬å–{len(promising_sites)}ä¸ªç½‘ç«™ (æ— æ—¶é—´é™åˆ¶)...")
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                    future_to_result = {
                        executor.submit(self.scrape_website_advanced, site['url']): site 
                        for site in promising_sites
                    }
                    
                    # ç§»é™¤è¶…æ—¶é™åˆ¶ï¼Œè®©æ‰€æœ‰ç½‘ç«™éƒ½æœ‰å……è¶³æ—¶é—´å®Œæˆ
                    for future in concurrent.futures.as_completed(future_to_result):
                        try:
                            site = future_to_result[future]
                            website_emails = future.result()

                            for email_data in website_emails:
                                total_emails_found += 1  # ğŸ”¥ FIX: Count all emails found
                                email_addr = email_data['email']
                                # ğŸ”¥ NEW: Skip already-returned emails
                                if email_addr in self.already_returned_emails:
                                    total_cached_skipped += 1  # ğŸ”¥ FIX: Track skipped
                                    continue
                                if not any(e['email'] == email_addr for e in round_emails):
                                    round_emails.append({
                                        'email': email_addr,
                                        'name': email_data.get('name'),
                                        'title': email_data.get('title'),
                                        'department': email_data.get('department'),
                                        'is_personal': email_data.get('is_personal', False),
                                        'source': 'website_scraping',
                                        'source_url': site['url'],
                                        'source_title': site.get('title', ''),
                                        'confidence': 0.95 if email_data.get('is_personal') else 0.8,
                                        'round': round_num,
                                        'strategy': strategy,
                                        'discovery_method': 'deep_scraping'
                                    })
                        except Exception as ex:
                            continue
                
                # æ£€æŸ¥è¿›åº¦ï¼Œä½†ä¸ç«‹å³åœæ­¢ - è®©å®ƒç»§ç»­æœç´¢æ›´å¤š
                all_unique = {e['email']: e for e in all_emails + round_emails}
                if len(all_unique) >= target_count:
                    self.logger.info(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡ï¼Œä½†ç»§ç»­æœç´¢ä»¥è·å¾—æ›´å‡†ç¡®ç»“æœ...")
                    # ä¸breakï¼Œç»§ç»­æœç´¢
                
                time.sleep(0.3)  # å‡å°‘ç­–ç•¥é—´éš”
            
            # æ›´æ–°æ€»é‚®ç®±åˆ—è¡¨
            all_emails.extend(round_emails)
            all_unique = {e['email']: e for e in all_emails}
            all_emails = list(all_unique.values())

            # ğŸ”¥ FIX: Show detailed statistics including cached skips
            self.logger.info(f"ğŸ“Š ç¬¬{round_num}è½®ç»“æœ: æ–°å¢{len(round_emails)}ä¸ªï¼Œæ€»è®¡{len(all_emails)}ä¸ªNEWé‚®ç®±")
            if total_cached_skipped > 0:
                self.logger.info(f"   ğŸ”„ å·²è·³è¿‡ {total_cached_skipped} ä¸ªé‡å¤/ç¼“å­˜é‚®ç®± (æ€»å‘ç°{total_emails_found}ä¸ª)")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥ï¼Œä½†ä¸è½»æ˜“æ”¾å¼ƒ
            if len(round_emails) == 0:
                consecutive_empty_rounds += 1
                self.logger.warning(f"âš ï¸ è¿ç»­{consecutive_empty_rounds}è½®æ— ç»“æœ - ç»§ç»­å°è¯•")
                
                if consecutive_empty_rounds >= 5:  # å¢åŠ å®¹å¿åº¦
                    self.logger.info("ğŸ”„ åˆ‡æ¢åˆ°æ›´å¹¿æ³›çš„æœç´¢ç­–ç•¥...")
            else:
                consecutive_empty_rounds = 0
            
            # å³ä½¿è¾¾åˆ°ç›®æ ‡ä¹Ÿä¸ç«‹å³é€€å‡º - ç»§ç»­æœç´¢è·å¾—æ›´å¤šé‚®ç®±
            if len(all_emails) >= target_count and round_num >= 5:
                self.logger.info(f"ğŸ¯ å·²æ”¶é›†è¶³å¤Ÿé‚®ç®±å¹¶è¿›è¡Œäº†å……åˆ†æœç´¢ï¼Œå‡†å¤‡ç»“æŸ")
                break
            
            round_num += 1
            if round_num <= max_rounds:
                time.sleep(1)  # å‡å°‘è½®æ¬¡é—´éš”
        
        # æ•´ç†æœ€ç»ˆç»“æœ
        final_emails = all_emails[:target_count]
        total_time = time.time() - start_time

        # æ›´æ–°ç»Ÿè®¡
        self.search_stats['emails_found'] = len(final_emails)

        # ğŸ”¥ FIX: Save newly returned emails to cache with session_id
        new_email_addresses = [e['email'] for e in final_emails]
        if new_email_addresses:
            self.save_returned_emails_cache(industry, new_email_addresses, session_id)
            self.logger.info(f"   âœ… å·²ä¿å­˜ {len(new_email_addresses)} ä¸ªæ–°é‚®ç®±åˆ°ç¼“å­˜")

        self.logger.info(f"\nğŸŠ è¶…çº§æœç´¢å®Œæˆï¼")
        self.logger.info(f"   ğŸ“§ æœ€ç»ˆé‚®ç®±: {len(final_emails)}ä¸ªNEWé‚®ç®± (å…¨éƒ¨ä¸ºæ–°å‘ç°)")
        self.logger.info(f"   ğŸ”„ æœç´¢è½®æ•°: {round_num-1}")
        self.logger.info(f"   â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’")
        self.logger.info(f"   ğŸ“Š æˆåŠŸç‡: {self.search_stats['successful_queries']}/{self.search_stats['total_queries']}")
        self.logger.info(f"   ğŸŒ çˆ¬å–ç½‘ç«™: {self.search_stats['websites_scraped']}ä¸ª")
        self.logger.info(f"   ğŸ¢ å‘ç°åŸŸå: {len(self.search_stats['unique_domains'])}ä¸ª")
        self.logger.info(f"   ğŸ”„ æ€»å‘ç°: {total_emails_found}ä¸ª (è·³è¿‡{total_cached_skipped}ä¸ªé‡å¤)")
        self.logger.info(f"   ğŸ—‚ï¸ ç¼“å­˜æ€»æ•°: {len(self.already_returned_emails)} ä¸ªå†å²é‚®ç®±")

        # æ˜¾ç¤ºå‘ç°çš„é‚®ç®±
        if final_emails:
            self.logger.info("\nğŸ“§ å‘ç°çš„é‚®ç®±åœ°å€ (æ–°):")
            for i, email_data in enumerate(final_emails, 1):
                self.logger.info(f"   {i}. {email_data['email']} (ç½®ä¿¡åº¦: {email_data['confidence']})")

        return {
            'success': len(final_emails) > 0,
            'emails': [e['email'] for e in final_emails],
            'email_details': final_emails,
            'total_emails': len(final_emails),
            'search_rounds': round_num - 1,
            'execution_time': total_time,
            'search_stats': self.prepare_stats_for_json(),
            'industry': industry,
            'target_achieved': len(final_emails) >= target_count,
            'method': 'super_email_discovery_2024',
            'confidence_score': sum(e['confidence'] for e in final_emails) / len(final_emails) if final_emails else 0,
            'timestamp': datetime.now().isoformat()
        }
    
    def prepare_stats_for_json(self):
        """å‡†å¤‡ç»Ÿè®¡æ•°æ®ç”¨äºJSONåºåˆ—åŒ–"""
        stats = dict(self.search_stats)
        stats['unique_domains'] = list(self.search_stats['unique_domains'])
        return stats

def main():
    if len(sys.argv) < 2:
        print('ä½¿ç”¨æ–¹æ³•: python3 SuperEmailDiscoveryEngine.py "è¡Œä¸šåç§°" [é‚®ç®±æ•°é‡] [session_id]')
        print('ç¤ºä¾‹: python3 SuperEmailDiscoveryEngine.py "AI startup" 5 campaign_123')
        return

    industry = sys.argv[1]
    target_count = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    session_id = sys.argv[3] if len(sys.argv) > 3 else None  # ğŸ”¥ FIX: Accept session_id

    engine = SuperEmailDiscoveryEngine()
    # ğŸ”¥ FIX: Let max_rounds be calculated dynamically based on target_count
    results = engine.execute_persistent_discovery(industry, target_count, session_id=session_id)
    
    print("\n" + "="*90)
    print("ğŸ¯ è¶…çº§é‚®ç®±æœç´¢å¼•æ“ - æœ€ç»ˆæŠ¥å‘Š")
    print("="*90)
    
    if results['success']:
        print(f"âœ… æˆåŠŸå‘ç° {results['total_emails']} ä¸ªé‚®ç®±åœ°å€:")
        for i, email in enumerate(results['emails'], 1):
            print(f"   {i}. {email}")
        
        print(f"\nğŸ“Š æœç´¢æ€§èƒ½æŒ‡æ ‡:")
        print(f"   ğŸ”„ æœç´¢è½®æ•°: {results['search_rounds']}")
        print(f"   â±ï¸ æ€»è€—æ—¶: {results['execution_time']:.1f}ç§’")
        print(f"   ğŸ¯ ç›®æ ‡è¾¾æˆ: {'æ˜¯' if results['target_achieved'] else 'å¦'}")
        print(f"   ğŸ“ˆ æŸ¥è¯¢æˆåŠŸç‡: {results['search_stats']['successful_queries']}/{results['search_stats']['total_queries']}")
        print(f"   ğŸŒ ç½‘ç«™çˆ¬å–: {results['search_stats']['websites_scraped']}ä¸ª")
        print(f"   ğŸ¢ å‘ç°åŸŸå: {len(results['search_stats']['unique_domains'])}ä¸ª")
        print(f"   ğŸ­ å¹³å‡ç½®ä¿¡åº¦: {results['confidence_score']:.2f}")
        
    else:
        print("âŒ æœªèƒ½å‘ç°é‚®ç®±åœ°å€")
        print("ğŸ’¡ å»ºè®®ï¼šå°è¯•æ›´å…·ä½“çš„è¡Œä¸šæè¿°æˆ–å¢åŠ æœç´¢è½®æ•°")
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ (JSON):")
    print(json.dumps(results, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()