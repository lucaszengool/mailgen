#!/usr/bin/env python3
"""
Simple Web Email Search
ç®€å•ç›´æ¥çš„ç½‘ç»œé‚®ç®±æœç´¢ - ä¸ä¾èµ–å¤æ‚çš„LLM function calling
- ç›´æ¥æœç´¢ç½‘ç»œ
- æ™ºèƒ½é‚®ç®±æå–
- å¿«é€Ÿè¿”å›ç»“æœ
- é›¶å¤æ‚ä¾èµ–
"""

import sys
import json
import time
import re
import requests
import os
from datetime import datetime
from urllib.parse import quote, unquote
from bs4 import BeautifulSoup
import random

class SimpleWebEmailSearch:
    def __init__(self):
        # æœç´¢ä¼šè¯é…ç½®
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        # é‚®ç®±åŒ¹é…
        self.email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        
        print("ğŸ” Simple Web Email Search åˆå§‹åŒ–")
        print("   ğŸŒ æœç´¢å¼•æ“: DuckDuckGo + Bing")
        print("   ğŸ“§ é‚®ç®±å‘ç°: ç›´æ¥æå–")
        print("   âš¡ ç‰¹ç‚¹: å¿«é€Ÿã€ç®€å•ã€å¯é ")
        
    def search_duckduckgo(self, query):
        """DuckDuckGoæœç´¢"""
        try:
            print(f"   ğŸ¦† DuckDuckGo: {query}")
            
            search_url = f"https://duckduckgo.com/html/?q={quote(query)}"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                results = []
                
                for link in soup.find_all('a', class_='result__a')[:10]:
                    try:
                        title = link.get_text().strip()
                        url = link.get('href', '')
                        
                        parent = link.find_parent('div', class_='result')
                        description = ''
                        if parent:
                            snippet = parent.find('a', class_='result__snippet')
                            if snippet:
                                description = snippet.get_text().strip()
                        
                        if title and url and 'duckduckgo.com' not in url:
                            results.append({
                                'title': title,
                                'url': url,
                                'description': description
                            })
                    except:
                        continue
                
                print(f"      âœ… {len(results)}ä¸ªç»“æœ")
                return results
            else:
                print(f"      âŒ å¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"      âŒ é”™è¯¯: {str(e)}")
            return []
    
    def extract_emails_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆé‚®ç®±"""
        emails = self.email_pattern.findall(text)
        
        valid_emails = []
        for email in emails:
            email_lower = email.lower()
            
            # æ’é™¤å‡é‚®ç®±
            if any(pattern in email_lower for pattern in [
                'example.com', 'test.com', 'domain.com', 'yoursite.com',
                'noreply', 'no-reply', 'donotreply', 'privacy@', 'legal@'
            ]):
                continue
            
            # åŸºæœ¬éªŒè¯
            if 5 < len(email) < 100 and email.count('@') == 1:
                domain = email.split('@')[1]
                if '.' in domain and len(domain) > 4:
                    valid_emails.append(email)
        
        return valid_emails
    
    def scrape_website(self, url):
        """æŠ“å–ç½‘ç«™å†…å®¹"""
        try:
            print(f"      ğŸŒ æŠ“å–: {url[:50]}...")
            
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ç§»é™¤æ— ç”¨å…ƒç´ 
                for element in soup(["script", "style", "nav", "footer"]):
                    element.decompose()
                
                text = soup.get_text()
                emails = self.extract_emails_from_text(text)
                
                if emails:
                    print(f"         âœ… æ‰¾åˆ°{len(emails)}ä¸ªé‚®ç®±")
                    return emails
                else:
                    print(f"         âš ï¸  æœªæ‰¾åˆ°é‚®ç®±")
                    return []
                    
            else:
                print(f"         âŒ å¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"         âŒ é”™è¯¯: {str(e)}")
            return []
    
    def search_for_emails(self, industry, max_emails=5):
        """æœç´¢é‚®ç®±çš„ä¸»æ–¹æ³•"""
        print(f"ğŸ” å¼€å§‹æœç´¢ {industry} è¡Œä¸šé‚®ç®±")
        print(f"ğŸ¯ ç›®æ ‡: {max_emails}ä¸ªé‚®ç®±")
        print("=" * 50)
        
        all_emails = []
        
        # å¤šä¸ªæœç´¢æŸ¥è¯¢
        search_queries = [
            f"{industry} company contact email",
            f"{industry} business email address",
            f"{industry} company CEO founder email",
            f"{industry} startup contact information"
        ]
        
        for i, query in enumerate(search_queries, 1):
            print(f"\nğŸ“ æœç´¢ç­–ç•¥ {i}/{len(search_queries)}: {query}")
            
            # æœç´¢
            results = self.search_duckduckgo(query)
            
            if results:
                # ä»æœç´¢ç»“æœæè¿°ä¸­æå–é‚®ç®±
                print(f"   ğŸ“§ ä»æœç´¢ç»“æœä¸­æå–é‚®ç®±...")
                for result in results:
                    text = f"{result['title']} {result['description']}"
                    emails = self.extract_emails_from_text(text)
                    
                    for email in emails:
                        if email not in all_emails:
                            all_emails.append(email)
                            print(f"      âœ… æ‰¾åˆ°: {email}")
                
                # æŠ“å–å‰5ä¸ªç½‘ç«™
                print(f"   ğŸŒ æŠ“å–å‰5ä¸ªç½‘ç«™...")
                for result in results[:5]:
                    if len(all_emails) >= max_emails:
                        break
                        
                    website_emails = self.scrape_website(result['url'])
                    for email in website_emails:
                        if email not in all_emails:
                            all_emails.append(email)
                            print(f"      âœ… ç½‘ç«™æ‰¾åˆ°: {email}")
                    
                    time.sleep(1)  # æŠ“å–é—´éš”
            
            # å¦‚æœå·²æ‰¾åˆ°è¶³å¤Ÿé‚®ç®±å°±åœæ­¢
            if len(all_emails) >= max_emails:
                print(f"   ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡é‚®ç®±æ•°é‡")
                break
            
            # æŸ¥è¯¢é—´éš”
            time.sleep(2)
        
        final_emails = all_emails[:max_emails]
        
        print(f"\nğŸ‰ æœç´¢å®Œæˆ!")
        print(f"   ğŸ“§ æ‰¾åˆ°é‚®ç®±: {len(final_emails)}ä¸ª")
        
        return final_emails

def main():
    if len(sys.argv) < 2:
        print(json.dumps({'error': 'è¯·æä¾›è¡Œä¸šåç§° (ä¾‹å¦‚: "AI startup", "fruit companies")'}))
        return
    
    industry = sys.argv[1]
    max_emails = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    
    # æ‰§è¡Œæœç´¢
    searcher = SimpleWebEmailSearch()
    emails = searcher.search_for_emails(industry, max_emails)
    
    # å‡†å¤‡è¾“å‡º
    output = {
        'success': True,
        'emails': emails,
        'total_emails': len(emails),
        'industry': industry,
        'search_method': 'simple_web_email_search',
        'fast_and_reliable': True,
        'timestamp': datetime.now().isoformat()
    }
    
    print("\n" + "=" * 50)
    print("ğŸ” Simple Web Email Search ç»“æœ")
    print("=" * 50)
    
    if emails:
        print("ğŸ“§ å‘ç°çš„é‚®ç®±:")
        for i, email in enumerate(emails, 1):
            print(f"   {i}. {email}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°é‚®ç®±")
    
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   ğŸ“§ é‚®ç®±æ€»æ•°: {len(emails)}")
    print(f"   ğŸŒ æœç´¢å¼•æ“: DuckDuckGo")
    print(f"   âš¡ æ–¹æ³•: ç®€å•ç›´æ¥")
    
    print(json.dumps(output, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()